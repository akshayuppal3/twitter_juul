{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import git\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_root(path):\n",
    "\tgit_repo = git.Repo(path, search_parent_directories=True)\n",
    "\tgit_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "\treturn git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = get_git_root(os.getcwd())\n",
    "input_dir = os.path.join(top_dir,\"input\")\n",
    "extraction_new_dir = os.path.join(input_dir,\"hexagon_extract_new\")\n",
    "extraction_rem_dir = os.path.join(input_dir,\"hexagon_extract\")\n",
    "model_dir = os.path.join(get_git_root(os.getcwd()),\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def get_consolidated(dir_path):\n",
    "    files = [file for file in os.listdir(dir_path) if file.endswith(\".csv\")]\n",
    "    li = []\n",
    "    for file in tqdm(files):\n",
    "        file_path = os.path.join(dir_path,file,)\n",
    "        df_temp = pd.read_csv(file_path,lineterminator= \"\\n\")\n",
    "        li.append(df_temp)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(input_dir,\"weed_data_extract\")\n",
    "df_weed = pd.concat(frames,axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10420444"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_weed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_weed.userID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(input_dir,\"weed_data.csv\"),lineterminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['favourites_count', 'followersCount', 'friendsCount', 'hashtags',\n",
       "       'imageurl', 'lang', 'listedCount', 'retweetCount', 'retweetText',\n",
       "       'retweeted', 'statusesCount', 'tweetCreatedAt', 'tweetId', 'tweetText',\n",
       "       'url', 'userCreatedAt', 'userDescription', 'userHandle', 'userID',\n",
       "       'userLocation', 'userName'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub = df[['favourites_count','followersCount', 'friendsCount', 'hashtags','listedCount', 'retweetCount', 'retweetText',\n",
    "#        'retweeted', 'statusesCount', 'tweetCreatedAt', 'tweetId', 'tweetText', 'userID',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.to_csv(os.path.join(input_dir,\"weed_data_sub.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one file for just tweetText and userID\n",
    "# df_sub = df[['hashtags','retweetText','tweetCreatedAt','tweetId', 'tweetText','userID',]]\n",
    "# df_sub.to_csv(os.path.join(input_dir,\"weed_data_text.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drew_william2345/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_sub = pd.read_csv(os.path.join(input_dir,\"weed_data_text.csv\"),lineterminator=\"\\n\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_ = df_sub.loc[df_sub['retweetText'].notnull()][\"tweetId\"]\n",
    "df_sub.loc[df_sub.tweetId.isin(ids_),\"tweetText\"] = df_sub.loc[df_sub.tweetId.isin(ids_)][\"retweetText\"]\n",
    "df_sub = df_sub.drop([\"hashtags\",\"retweetText\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(os.path.join(input_dir,\"weed_data_text2.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:          20072         348       15360           0        4363       19372\r\n",
      "Swap:             0           0           0\r\n"
     ]
    }
   ],
   "source": [
    "! free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/drew_william2345/twitter_juul/input/weed_data_text2.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "- [1 files][  1.6 GiB/  1.6 GiB]   19.7 MiB/s                                   \n",
      "Operation completed over 1 objects/1.6 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp /home/drew_william2345/twitter_juul/input/weed_data_text2.csv gs://juul1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
