{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import git\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_root(path):\n",
    "\tgit_repo = git.Repo(path, search_parent_directories=True)\n",
    "\tgit_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "\treturn git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = get_git_root(os.getcwd())\n",
    "input_dir = os.path.join(top_dir,\"input\")\n",
    "extraction_new_dir = os.path.join(input_dir,\"hexagon_extract_new\")\n",
    "extraction_rem_dir = os.path.join(input_dir,\"hexagon_extract\")\n",
    "model_dir = os.path.join(get_git_root(os.getcwd()),\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def get_consolidated(dir_path):\n",
    "    files = [file for file in os.listdir(dir_path) if file.endswith(\".csv\")]\n",
    "    li = []\n",
    "    for file in tqdm(files):\n",
    "        file_path = os.path.join(dir_path,file,)\n",
    "        df_temp = pd.read_csv(file_path,lineterminator= \"\\n\")\n",
    "        li.append(df_temp)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### consolidating the files for weed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(input_dir,\"weed_data_extract\")\n",
    "df_weed = pd.concat(frames,axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10420444"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_weed))\n",
    "print(len(df_weed.userID.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merging the weed and juul data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weed = pd.read_csv(os.path.join(input_dir,\"weed_data.csv\"),lineterminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sub file for just tweetText and userID\n",
    "df_sub = df[['favourites_count','followersCount', 'friendsCount', 'hashtags','listedCount', 'retweetCount', 'retweetText',\n",
    "       'retweeted', 'statusesCount', 'tweetCreatedAt', 'tweetId', 'tweetText', 'userID',]]\n",
    "\n",
    "df_sub.to_csv(os.path.join(input_dir,\"weed_data_sub.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one file for just tweetText and userID\n",
    "df_sub = df[['hashtags','retweetText','tweetCreatedAt','tweetId', 'tweetText','userID',]]\n",
    "df_sub.to_csv(os.path.join(input_dir,\"weed_data_text.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one file for just tweetText and userID with retweetText column removed\n",
    "df_sub = pd.read_csv(os.path.join(input_dir,\"weed_data_text.csv\"),lineterminator=\"\\n\",index_col=0)\n",
    "ids_ = df_sub.loc[df_sub['retweetText'].notnull()][\"tweetId\"]\n",
    "df_sub.loc[df_sub.tweetId.isin(ids_),\"tweetText\"] = df_sub.loc[df_sub.tweetId.isin(ids_)][\"retweetText\"]\n",
    "df_sub = df_sub.drop([\"hashtags\",\"retweetText\"],axis=1)\n",
    "df_sub.to_csv(os.path.join(input_dir,\"weed_data_text2.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging with selected columns (reducing the size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weed_users 554815\n",
      "weed_data, 10420444\n",
      "\n",
      "juul_users 887180\n",
      "juul data 1692201\n"
     ]
    }
   ],
   "source": [
    "## merging juul and weed data\n",
    "df_weed = pd.read_csv(os.path.join(input_dir,\"weed_data_text2.csv\"),lineterminator=\"\\n\")\n",
    "df_juul = pd.read_csv(os.path.join(input_dir,\"juul_data.csv\"),lineterminator=\"\\n\")\n",
    "\n",
    "weed_users = (df_weed.userID.unique())\n",
    "print(\"weed_users\",len(weed_users))\n",
    "print(\"weed_data,\",len(df_weed))\n",
    "\n",
    "print()\n",
    "juul_users =(df_juul.userID.unique())\n",
    "print(\"juul_users\",len(juul_users))\n",
    "print(\"juul data\",len(df_juul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1692201\n",
      "1671156\n"
     ]
    }
   ],
   "source": [
    "## regex will not cover everything, our data itself has been curated using the boolean so we dont need to do matching\n",
    "print(len(df_juul))\n",
    "print(len(df_juul.loc[df_juul.tweetText.str.contains(\"juul|Juul|#juul\",case=False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juul users 887180\n"
     ]
    }
   ],
   "source": [
    "## removing rest of the columns not required\n",
    "tweetIDs = df_juul[\"tweetId\"].loc[df_juul[\"retweetText\"].notnull()]\n",
    "df_juul.loc[df_juul.tweetId.isin(tweetIDs),\"tweetText\"] = df_juul.loc[df_juul.tweetId.isin(tweetIDs)][\"retweetText\"]\n",
    "print(\"juul users\",len(df_juul.userID.unique())) ## sanity check\n",
    "df_juul = df_juul[list(df_weed.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_weed,df_juul]\n",
    "df_dataset = pd.concat(frames,ignore_index=True)\n",
    "columns = [\"userID\",\"tweetId\",\"tweetCreatedAt\",\"tweetText\"]\n",
    "df_dataset = df_dataset[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554\n"
     ]
    }
   ],
   "source": [
    "## there are some extra users\n",
    "extra_users = (list(set(weed_users) - set(juul_users)))\n",
    "print(len(extra_users))\n",
    "## it does not make sense to add data that were never teh part of extraction process so we filter it\n",
    "df_dataset = (df_dataset.loc[~df_dataset.userID.isin(extra_users)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12088584\n",
      "887180\n"
     ]
    }
   ],
   "source": [
    "print(len(df_dataset))\n",
    "print(len(df_dataset.userID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.to_csv(os.path.join(input_dir,\"dataset.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12088584\n",
      "887180\n"
     ]
    }
   ],
   "source": [
    "## looking at the merged data ## sanity check\n",
    "df_dataset = pd.read_csv(os.path.join(input_dir,\"dataset.csv\"),lineterminator=\"\\n\")\n",
    "print(len(df_dataset))   # 12,088,584\n",
    "print(len(df_dataset.userID.unique())) # 887,180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the first occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weed = df_weed.sort_values(by=[\"tweetCreatedAt\"])\n",
    "df_weed[\"tweetCreatedAt\"] = pd.to_datetime(df_weed[\"tweetCreatedAt\"])\n",
    "first_weed = df_weed.groupby([\"userID\"])[\"tweetCreatedAt\"].first()\n",
    "first_weed = first_weed.reset_index()\n",
    "\n",
    "## get the first occurance for juul\n",
    "df_juul = df_juul.sort_values(by=[\"tweetCreatedAt\"])\n",
    "df_juul[\"tweetCreatedAt\"] = pd.to_datetime(df_juul[\"tweetCreatedAt\"])\n",
    "first_juul = df_juul.groupby([\"userID\"])[\"tweetCreatedAt\"].first()\n",
    "first_juul = first_juul.reset_index()\n",
    "\n",
    "# columns\n",
    "first_weed.columns = [\"userID\",\"weed_first\"]\n",
    "first_juul.columns = [\"userID\",\"juul_first\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inner join to forms first of both weed and juul (it will be left as there are some extra users in weed_data)\n",
    "first_data = (first_juul.join(first_weed.set_index(\"userID\"),on='userID',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data.to_csv(os.path.join(input_dir,\"user_first.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data = pd.read_csv(os.path.join(input_dir,\"user_first.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juul",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
