{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import git\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_root(path):\n",
    "\tgit_repo = git.Repo(path, search_parent_directories=True)\n",
    "\tgit_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "\treturn git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = get_git_root(os.getcwd())\n",
    "input_dir = os.path.join(top_dir,\"input\")\n",
    "extraction_new_dir = os.path.join(input_dir,\"hexagon_extract_new\")\n",
    "extraction_rem_dir = os.path.join(input_dir,\"hexagon_extract\")\n",
    "model_dir = os.path.join(get_git_root(os.getcwd()),\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def get_consolidated(dir_path):\n",
    "    files = [file for file in os.listdir(dir_path) if file.endswith(\".csv\")]\n",
    "    li = []\n",
    "    for file in tqdm(files):\n",
    "        file_path = os.path.join(dir_path,file,)\n",
    "        df_temp = pd.read_csv(file_path,lineterminator= \"\\n\")\n",
    "        li.append(df_temp)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(input_dir,\"weed_data_extract\")\n",
    "df_weed = pd.concat(frames,axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10420444"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_weed))\n",
    "print(len(df_weed.userID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(input_dir,\"weed_data.csv\"),lineterminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sub file for just tweetText and userID\n",
    "df_sub = df[['favourites_count','followersCount', 'friendsCount', 'hashtags','listedCount', 'retweetCount', 'retweetText',\n",
    "       'retweeted', 'statusesCount', 'tweetCreatedAt', 'tweetId', 'tweetText', 'userID',]]\n",
    "\n",
    "df_sub.to_csv(os.path.join(input_dir,\"weed_data_sub.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one file for just tweetText and userID\n",
    "df_sub = df[['hashtags','retweetText','tweetCreatedAt','tweetId', 'tweetText','userID',]]\n",
    "df_sub.to_csv(os.path.join(input_dir,\"weed_data_text.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one file for just tweetText and userID with retweetText column removed\n",
    "df_sub = pd.read_csv(os.path.join(input_dir,\"weed_data_text.csv\"),lineterminator=\"\\n\",index_col=0)\n",
    "ids_ = df_sub.loc[df_sub['retweetText'].notnull()][\"tweetId\"]\n",
    "df_sub.loc[df_sub.tweetId.isin(ids_),\"tweetText\"] = df_sub.loc[df_sub.tweetId.isin(ids_)][\"retweetText\"]\n",
    "df_sub = df_sub.drop([\"hashtags\",\"retweetText\"],axis=1)\n",
    "df_sub.to_csv(os.path.join(input_dir,\"weed_data_text2.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## merging juul and weed data\n",
    "df_weed = pd.read_csv(os.path.join(input_dir,\"weed_data_text2.csv\"),lineterminator=\"\\n\")\n",
    "df_juul = pd.read_csv(os.path.join(input_dir,\"juul_data.csv\"),lineterminator=\"\\n\")\n",
    "\n",
    "## combine both the data for the common set of users for juul\n",
    "weed_users = set(df_weed.userID.unique())\n",
    "users_common = ((weed_users).intersection(set(df_juul.userID.unique())))\n",
    "df_weed_sel = df_weed.loc[df_weed.userID.isin(users_common)]\n",
    "df_juul_sel = df_juul.loc[df_juul.userID.isin(users_common)]\n",
    "\n",
    "## removing rest of the columns not required\n",
    "tweetIDs = df_juul_sel[\"tweetId\"].loc[df_juul_sel[\"retweetText\"].notnull()]\n",
    "df_juul_sel.loc[df_juul_sel.tweetId.isin(tweetIDs),\"tweetText\"] = df_juul_sel.loc[df_juul_sel.tweetId.isin(tweetIDs)][\"retweetText\"]\n",
    "len(df_juul_sel.userID.unique()) ## sanity check\n",
    "df_juul_sel = df_juul_sel[list(df_weed_sel.columns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_juul_sel.userID.unique()))\n",
    "print(len(df_weed_sel.userID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_weed_sel))\n",
    "print(len(df_juul_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_juul_sel,df_weed_sel]\n",
    "df_dataset = pd.concat(frames,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"userID\",\"tweetId\",\"tweetCreatedAt\",\"tweetText\"]\n",
    "df_dataset = df_dataset[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11578887\n",
      "551261\n"
     ]
    }
   ],
   "source": [
    "print(len(df_dataset))\n",
    "print(len(df_dataset.userID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.to_csv(os.path.join(input_dir,\"dataset.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11578887\n",
      "551261\n"
     ]
    }
   ],
   "source": [
    "## looking at the merged data ## sanity check\n",
    "df_dataset = pd.read_csv(os.path.join(input_dir,\"dataset.csv\"),lineterminator=\"\\n\")\n",
    "print(len(df_dataset))   # 11,578,887\n",
    "print(len(df_dataset.userID.unique())) # 551,261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
